# Story-To-Video-Pipeline ğŸ¥âœ¨

An end-to-end AI pipeline that transforms your text prompt into a full animated story video using the power of Large Language Models (LLMs), Stable Diffusion, and text-to-speech narration.

---

## ğŸš€ Features

- âœ… **LLM-powered Story Generation** (using Mistral-7B)
- ğŸ¨ **AI Image Generation** (via Stable Diffusion)
- ğŸ™ï¸ **Text-to-Speech Narration** (gTTS)
- ğŸ¬ **Video Creation** (MoviePy)

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone https://github.com/krishrathi1/Story-To-Video-Pipeline.git
cd Story-To-Video-Pipeline
```

### 2. Install Required Packages
```bash
pip install -r requirements.txt
```

Or install them manually:
```bash
pip install transformers accelerate bitsandbytes huggingface_hub diffusers scipy safetensors gTTS moviepy
```

### 3. Set Your Hugging Face Token
```python
from huggingface_hub import login
login("<your_huggingface_token>")
```

### 4. Run the Pipeline
Run the Python file to:
- Generate a story from your prompt
- Create image scenes for the story
- Generate narration
- Compile the video

```bash
python story_to_video.py
```

---

## ğŸ§  Model Info
- **LLM Model**: Mistral-7B-Instruct-v0.1 (via Hugging Face)
- **Image Model**: Stable Diffusion v1.5 (`runwayml/stable-diffusion-v1-5`)
- **TTS**: Google Text-to-Speech (`gTTS`)

---

## ğŸ“ Output
- `story_video.mp4`: Final generated story video
- `story_images/`: AI-generated image scenes
- `narration.mp3`: Generated narration audio

---

## ğŸ“Œ Credits
Developed with â¤ï¸ by [Krish Rathi](https://github.com/krishrathi1)




